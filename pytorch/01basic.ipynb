{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cec55de",
   "metadata": {},
   "source": [
    "## Starting Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a9c15",
   "metadata": {},
   "source": [
    "#### Tensor Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a41df",
   "metadata": {},
   "source": [
    "1. Tensors\n",
    "    - Everything in PyTorch is based on Tensor operations. A Tensor is a multi dimensional matrix containing elements of a single data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d79e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty(1): tensor([0.])\n",
      "empty(3): tensor([0.])\n",
      "empty(2,3): tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "empty(2, 2, 3): tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "rand(5,3): tensor([[0.6801, 0.2567, 0.8993],\n",
      "        [0.3126, 0.4414, 0.5780],\n",
      "        [0.3521, 0.3500, 0.0722],\n",
      "        [0.8922, 0.7260, 0.8374],\n",
      "        [0.1239, 0.2635, 0.8099]])\n",
      "zeros(5,3): tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#torch.empty(size): uninitiallized\n",
    "\n",
    "x = torch.empty(1) #scalar\n",
    "\n",
    "print(\"empty(1):\", x)\n",
    "\n",
    "torch.empty(3) #vector\n",
    "\n",
    "print(\"empty(3):\",x)\n",
    "\n",
    "x = torch.empty(2, 3)# matrix\n",
    "\n",
    "print(\"empty(2,3):\",x)\n",
    "\n",
    "x = torch.empty(2, 2, 3) # tensor, 3 dimensions\n",
    "\n",
    "#x torch.empty(2,2,2,3) tensor, 4 dimensions\n",
    "\n",
    "print(\"empty(2, 2, 3):\",x)\n",
    "\n",
    "#torch.rand(size): random numbers [0, 1]\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "\n",
    "print(\"rand(5,3):\", x)\n",
    "\n",
    "#torch.zeros(size), fill with 0\n",
    "\n",
    "# torch.ones(size), fill with 1\n",
    "\n",
    "x = torch.zeros(5, 3)\n",
    "\n",
    "print(\"zeros(5,3):\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70fce33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size torch.Size([5, 3])\n",
      "shape torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"size\", x.size()) #x.size(0)\n",
    "print(\"shape\", x.shape)   # x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd6d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float16)\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "#Check dtypes\n",
    "\n",
    "print(x.dtype)\n",
    "\n",
    "#Specify types, float32 default\n",
    "x = torch.zeros(5, 3, dtype=torch.float16)\n",
    "print(x)\n",
    "\n",
    "#check type\n",
    "print(x.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a11c579",
   "metadata": {},
   "source": [
    "*Construct Tensor from Data or array*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c383e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5,3])\n",
    "print(x, x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463db391",
   "metadata": {},
   "source": [
    "*Intro to require_grad argument*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8afdd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#require_grad argument\n",
    "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
    "# later in your optimization steps\n",
    "#i.e. this is a variable in your model that you want to optimize\n",
    "\n",
    "x = torch.tensor([5.5,3], requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e85cc5",
   "metadata": {},
   "source": [
    "*Now if i perform any operation on my require_grad variable pytorch will keep track of it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "829c006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.6410, 0.9498],\n",
      "        [0.7711, 0.8171]])\n",
      "tensor([[1.6410, 1.9498],\n",
      "        [1.7711, 1.8171]])\n"
     ]
    }
   ],
   "source": [
    "# Operations\n",
    "x = torch.ones(2,2)\n",
    "y = torch.rand(2,2)\n",
    "\n",
    "# elementwise addition\n",
    "z = x + y\n",
    "# or\n",
    "#torch.add(x, y)\n",
    "\n",
    "# in place additon like it will modify the variable \n",
    "# y.add_(x)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb0b89ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substraction\n",
    "z = x - y\n",
    "z = torch.sub(x,y)\n",
    "\n",
    "# multiplication\n",
    "z = x * y\n",
    "z = torch.mul(x, y)\n",
    "\n",
    "# Division\n",
    "z = x / y\n",
    "z = torch.div(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40ec8f",
   "metadata": {},
   "source": [
    "*Slicing is also done with tensors like as normal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f7f6891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4969, 0.4550, 0.2381],\n",
      "        [0.2046, 0.0186, 0.2181],\n",
      "        [0.5149, 0.6615, 0.0525],\n",
      "        [0.7870, 0.0234, 0.7761],\n",
      "        [0.0280, 0.0648, 0.4552]])\n",
      "x[:, 0] tensor([0.4969, 0.2046, 0.5149, 0.7870, 0.0280])\n",
      "0.49685782194137573\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "\n",
    "print(x)\n",
    "print(\"x[:, 0]\", x[:, 0]) #all rows, column 0\n",
    "\n",
    "# get the actual value if only 1 element in tensor\n",
    "print(x[0,0].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5fb1ca",
   "metadata": {},
   "source": [
    "*Reshape the tensor using view*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44a846e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# reshape with torch.view()\n",
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 means it will automatically determine the necessary size\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b11f579",
   "metadata": {},
   "source": [
    "**Numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "115c0798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Converting tensor into numpy array and vice versa\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "#torch to numpy with .numpy()\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55367608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Careful if the Tensor is in CPU(not the GPU)\n",
    "# both objects will share the same memory location, so changing one\n",
    "# will also change the other\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc5273c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "c = torch.tensor(a)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "#again be careful when modifying\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738ab5c5",
   "metadata": {},
   "source": [
    "#### GPU Support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb13327",
   "metadata": {},
   "source": [
    "*By default all tensors are created on the CPU. But we can also move them to the GPU(if its available), or create them directly on the GPU.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "451803cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x = torch.rand(2,2).to(device)   # move tensors to GPU device\n",
    "#x = x.to('cpu')\n",
    "# x = x.to('cuda')\n",
    "\n",
    "x = torch.rand(2,2, device = device) # or directly create them on GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd66c8",
   "metadata": {},
   "source": [
    "#### AutoGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073c0c8",
   "metadata": {},
   "source": [
    "*This package provides automatic differentiation for all operations on Tensors.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8e77aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0588,  1.7982,  1.0857], requires_grad=True)\n",
      "tensor([1.9412, 3.7982, 3.0857], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x0000019D8775E2C0>\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x + 2\n",
    "\n",
    "# y was create a result of an operation so it has grad_fn attribute.\n",
    "# grad_fn: reference a function that has created the Tensor\n",
    "print(x)\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "725fa998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.3047, 43.2798, 28.5641], grad_fn=<MulBackward0>)\n",
      "tensor(27.7162, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Do more operations on y\n",
    "z = y*y*3\n",
    "print(z)\n",
    "z = z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64b3a330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.8824, 7.5965, 6.1713])\n"
     ]
    }
   ],
   "source": [
    "#Lets compute Gradient with backpropogation\n",
    "# when we finish our computation we can call .backward() and have all the gradients computed\n",
    "# the gradient for this tensor will be acculmulated into .grad attribute\n",
    "# It is the partial derivative of the function w.r.t. the tensor\n",
    "\n",
    "z.backward()\n",
    "print(x.grad) # dz/dx\n",
    "\n",
    "# !! Careful .backward() accumulated the gradient in grad attribute for this tensor\n",
    "# we need to be careful during optimization to clear it, before reusing by optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ccee7",
   "metadata": {},
   "source": [
    "#### Stop a Tensor from tracking history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e97c92",
   "metadata": {},
   "source": [
    "For example during the training loop when we want to update our weights or after training when evaluation. these operations should not be part of gradient computation. to prevent this we can use:\n",
    "\n",
    "    - x.requires_grad_(False)\n",
    "    - x.detach()\n",
    "    - wrap in with torch.no_grad(:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f9ee016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "True\n",
      "<SumBackward0 object at 0x0000019D87B39B40>\n"
     ]
    }
   ],
   "source": [
    "# .requires_grad_(...) changes the existing flag in-place.\n",
    "a = torch.randn(2,2)\n",
    "b = (a * a).sum()\n",
    "print(a.requires_grad)\n",
    "print(b.grad_fn)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "b = (a * a).sum()\n",
    "print(a.requires_grad)\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6810c176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
    "a = torch.randn(2,2, requires_grad=True)\n",
    "b = a.detach()\n",
    "print(a.requires_grad)\n",
    "print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62198c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# wrap in 'with torch.no_grad():'\n",
    "a = torch.randn(2,2, requires_grad=True)\n",
    "print(a.requires_grad)\n",
    "with torch.no_grad():\n",
    "    b = a**2\n",
    "    print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3779ef8e",
   "metadata": {},
   "source": [
    "#### Gradient Descent Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e2887",
   "metadata": {},
   "source": [
    "Linear Regression example:\n",
    "\n",
    "*f(x)* = *w* * x + b\n",
    "\n",
    "    f(x) = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc89e45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before Training: f(5.0) = 0.000\n"
     ]
    }
   ],
   "source": [
    "# linear Regression\n",
    "# f = w * x + b \n",
    "# here  : f = 2 * x \n",
    "\n",
    "X = torch.tensor([1,2,3,4,5,6,7,8], dtype=torch.float32)\n",
    "y = torch.tensor([2,4,6,8,10,12,14,16], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model output\n",
    "def forward(X):\n",
    "    return w * X\n",
    "\n",
    "# loss = mse\n",
    "def loss(y, y_pred):\n",
    "    return ((y-y_pred)**2).mean()\n",
    "X_test = 5.0\n",
    "y_test = 10.0\n",
    "\n",
    "print(f'Prediction before Training: f({X_test}) = {forward(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b8ea3",
   "metadata": {},
   "source": [
    "*Training the Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "885b4691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: w = 1.998, loss = 0.000\n",
      "epoch 20: w = 2.000, loss = 0.000\n",
      "epoch 30: w = 2.000, loss = 0.000\n",
      "epoch 40: w = 2.000, loss = 0.000\n",
      "epoch 50: w = 2.000, loss = 0.000\n",
      "epoch 60: w = 2.000, loss = 0.000\n",
      "epoch 70: w = 2.000, loss = 0.000\n",
      "epoch 80: w = 2.000, loss = 0.000\n",
      "epoch 90: w = 2.000, loss = 0.000\n",
      "epoch 100: w = 2.000, loss = 0.000\n",
      "Predictions after training: f(5.0) = 10.000\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #predict\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "    # calculate gradient  = backward pass\n",
    "    l.backward()\n",
    "    \n",
    "    #update weights\n",
    "    # w.data = w.data - learning_rate * w.grad\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "        \n",
    "    # zero the gradients after updating(as grad accumulates)\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.3f}\")\n",
    "        \n",
    "print(f\"Predictions after training: f({X_test}) = {forward(X_test).item():.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b75ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c2ac0bd",
   "metadata": {},
   "source": [
    "#### Model, Loss and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c03552",
   "metadata": {},
   "source": [
    "A typical PyTorch Pipeline looks like this:\n",
    "\n",
    "1. Design model(input, output, forward pass with different layers)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loops:\n",
    "    - Forward = compute prediction and loss\n",
    "    - Backward = compute gradients\n",
    "    - Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1046dd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples = 8, n_features = 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x\n",
    "# here : f = 2 * x\n",
    "\n",
    "# 0) Training samples, watch the shape:\n",
    "X = torch.tensor([[1],[2],[3], [4], [5], [6], [7], [8]], dtype=torch.float32)\n",
    "y = torch.tensor([[2], [4], [6], [8], [10], [12],[14], [16]], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(f'n_samples = {n_samples}, n_features = {n_features}')\n",
    "\n",
    "# 0) create a test sample\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10981335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Before training: f(5.0) = -4.712\n",
      "epoch 10: w = 1.9698002338409424, loss = 0.005676873028278351\n",
      "epoch 20: w = 1.9725481271743774, loss = 0.004944734275341034\n",
      "epoch 30: w = 1.9736254215240479, loss = 0.004564512521028519\n",
      "epoch 40: w = 1.97465980052948, loss = 0.004213559906929731\n",
      "epoch 50: w = 1.9756534099578857, loss = 0.003889568615704775\n",
      "epoch 60: w = 1.976608157157898, loss = 0.003590524662286043\n",
      "epoch 70: w = 1.9775254726409912, loss = 0.0033144361805170774\n",
      "epoch 80: w = 1.9784067869186401, loss = 0.0030595939606428146\n",
      "epoch 90: w = 1.9792535305023193, loss = 0.00282433838583529\n",
      "epoch 100: w = 1.9800670146942139, loss = 0.0026071728207170963\n",
      "Prediction after training: f(5.0) = 10.012\n"
     ]
    }
   ],
   "source": [
    "# 1) Design Model, the model has to implement the forward pass:\n",
    "\n",
    "# Here we could simply use a built-in model from PyTorch\n",
    "# model = nn.Linear(input_size, output_size)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        #define different layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "input_size, output_size = n_features, n_features\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "print(f\"Prediction Before training: f({X_test.item()}) = {model(X_test).item():.3f}\")\n",
    "\n",
    "\n",
    "# 2) Define loss and optimizer\n",
    "learning_rate = 0.01\n",
    "n_epochs = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 3) Training Loop\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # predict\n",
    "    y_predicted = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l=loss(y, y_predicted)\n",
    "    \n",
    "    # calculate gradient = backward pass \n",
    "    l.backward()\n",
    "    \n",
    "    #optimizer\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Zero the gradient after updating\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if(epoch+1) % 10 == 0:\n",
    "        w, b = model.parameters() # unpack parameters\n",
    "        print(f\"epoch {epoch+1}: w = {w[0][0].item()}, loss = {l.item()}\")\n",
    "        \n",
    "print(f\"Prediction after training: f({X_test.item()}) = {model(X_test).item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136533d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
